{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "h_nn_gan_a.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sychun/colab/blob/master/h_nn_gan_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tR2wVzkxuDa"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egqJdLbWyDRb",
        "outputId": "f747cf41-da41-4fdd-81e5-ad5032822ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "text = open(path).read().lower()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNxHww_9yuBV",
        "outputId": "5312e58b-0714-4c9f-fdcd-37255ef3e35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print( len(text) )\n",
        "text[:30]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'preface\\n\\n\\nsupposing that truth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N-Oo9S3yybt",
        "outputId": "b1e51adc-ed99-4605-b129-566b7d3c88c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# 60개 글자로 된 시퀀스를 추출합니다.\n",
        "maxlen = 60\n",
        "\n",
        "# 세 글자씩 건너 뛰면서 새로운 시퀀스를 샘플링합니다.\n",
        "step = 3\n",
        "\n",
        "# 추출한 시퀀스를 담을 리스트\n",
        "sentences = []\n",
        "\n",
        "# 타깃(시퀀스 다음 글자)을 담을 리스트\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('시퀀스 개수:', len(sentences))\n",
        "\n",
        "# 말뭉치에서 고유한 글자를 담은 리스트\n",
        "chars = sorted(list(set(text)))\n",
        "print('고유한 글자:', len(chars))\n",
        "# chars 리스트에 있는 글자와 글자의 인덱스를 매핑한 딕셔너리\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# 글자를 원-핫 인코딩하여 0과 1의 이진 배열로 바꿉니다.\n",
        "print('벡터화...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "시퀀스 개수: 200278\n",
            "고유한 글자: 57\n",
            "벡터화...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVv7P5AGz2YO",
        "outputId": "f98827bb-350e-4c8b-e60f-c32f0d3b0884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print( len(chars) )\n",
        "print( x.shape, y.shape )\n",
        "# print( x[0] )\n",
        "# np.argmax(x[0], axis=1)\n",
        "# np.max(x[0], axis=1)\n",
        "char_indices"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57\n",
            "(200278, 60, 57) (200278, 57)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " \"'\": 4,\n",
              " '(': 5,\n",
              " ')': 6,\n",
              " ',': 7,\n",
              " '-': 8,\n",
              " '.': 9,\n",
              " '0': 10,\n",
              " '1': 11,\n",
              " '2': 12,\n",
              " '3': 13,\n",
              " '4': 14,\n",
              " '5': 15,\n",
              " '6': 16,\n",
              " '7': 17,\n",
              " '8': 18,\n",
              " '9': 19,\n",
              " ':': 20,\n",
              " ';': 21,\n",
              " '=': 22,\n",
              " '?': 23,\n",
              " '[': 24,\n",
              " ']': 25,\n",
              " '_': 26,\n",
              " 'a': 27,\n",
              " 'b': 28,\n",
              " 'c': 29,\n",
              " 'd': 30,\n",
              " 'e': 31,\n",
              " 'f': 32,\n",
              " 'g': 33,\n",
              " 'h': 34,\n",
              " 'i': 35,\n",
              " 'j': 36,\n",
              " 'k': 37,\n",
              " 'l': 38,\n",
              " 'm': 39,\n",
              " 'n': 40,\n",
              " 'o': 41,\n",
              " 'p': 42,\n",
              " 'q': 43,\n",
              " 'r': 44,\n",
              " 's': 45,\n",
              " 't': 46,\n",
              " 'u': 47,\n",
              " 'v': 48,\n",
              " 'w': 49,\n",
              " 'x': 50,\n",
              " 'y': 51,\n",
              " 'z': 52,\n",
              " 'ä': 53,\n",
              " 'æ': 54,\n",
              " 'é': 55,\n",
              " 'ë': 56}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWSoLFM0Ro_"
      },
      "source": [
        "from tensorflow.keras import layers, models, optimizers"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJD7-Tmq8I5A"
      },
      "source": [
        "model = models.Sequential()\n",
        "# model.add(layers.LSTM(128, input_shape=(60, 57))\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oJnH7RU98yh",
        "outputId": "82e1bb9b-07ad-4798-a315-da9bfc168c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               95232     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 57)                7353      \n",
            "=================================================================\n",
            "Total params: 102,585\n",
            "Trainable params: 102,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NaiAwFs-BqY",
        "outputId": "8f59c498-a431-4a83-b7f3-e3ae4bbbc5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=0.01))\n",
        "model.fit(x, y, batch_size=128, epochs=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1565/1565 [==============================] - 9s 6ms/step - loss: 1.9624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9df6629c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmklrDzD-ZeA"
      },
      "source": [
        "input_text = text[100:100+maxlen]\n",
        "input = np.zeros((1, maxlen, len(chars)))\n",
        "for idx, c in enumerate(input_text):\n",
        "  # print(idx, c)\n",
        "  input[0, idx, char_indices[c]] = 1.\n",
        "# print(input)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz-YS9oEAC1t",
        "outputId": "f93a954a-a5eb-440d-8385-88198760b462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# model.predict(input)[0].sum()\n",
        "idx = model.predict(input)[0].argmax()\n",
        "print(input_text)\n",
        "print(idx)\n",
        "#char_indices"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ilosophers, in so far as they have been\n",
            "dogmatists, have fai\n",
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQPpVQyHBZY4"
      },
      "source": [
        "# 예측된 각 문자의 확률을 조정하고 확률적 랜덤 샘플링\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4RwCTcGAvf",
        "outputId": "4d106197-df65-4af2-9b5d-baf3d7349fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "random.seed(42)\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "\n",
        "# 60 에포크 동안 모델을 훈련합니다\n",
        "# for epoch in range(1, 60):\n",
        "for epoch in range(1, 3):\n",
        "    print('에포크', epoch)\n",
        "    # 데이터에서 한 번만 반복해서 모델을 학습합니다\n",
        "    model.fit(x, y, batch_size=128, epochs=1)\n",
        "\n",
        "    # 무작위로 시드 텍스트를 선택합니다\n",
        "    seed_text = text[start_index: start_index + maxlen]\n",
        "    print('--- 시드 텍스트: \"' + seed_text + '\"')\n",
        "\n",
        "    # 여러가지 샘플링 온도를 시도합니다\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ 온도:', temperature)\n",
        "        generated_text = seed_text\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # 시드 텍스트에서 시작해서 400개의 글자를 생성합니다\n",
        "        for i in range(400):\n",
        "            # 지금까지 생성된 글자를 원-핫 인코딩으로 바꿉니다\n",
        "            sampled = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            # 다음 글자를 샘플링합니다\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크 1\n",
            "1565/1565 [==============================] - 9s 6ms/step - loss: 1.6138\n",
            "--- 시드 텍스트: \"the slowly ascending ranks and classes, in which,\n",
            "through fo\"\n",
            "------ 온도: 0.2\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for the sensition of the sense and more and and and as a condition of the sense of the sense and and and deed in the condition of the been the sense of the sense and and self-concerdent of the the sense and and so groment of the most delight and and and and and the sense and so man and a still and a still and the sense and science and and and the sense and the sense and strength and and the religiou\n",
            "------ 온도: 0.5\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for is an ancion and blone and a might and the desire of\n",
            "generality and one a delightion and because of convention of the standterness of power they has the far in the delights and refine the antarity, and such the most stander and are has himself in the intereding to be a soul the still be and sumple of the action and stall disting of moment himself and blied and ass not we and the sense and servin\n",
            "------ 온도: 1.0\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through formure aways is new\n",
            "take by gelou and \n",
            "find himself.--the more is not de lively, on\n",
            "the lancimation. not seepfust,\n",
            "graws on,\n",
            "kind of life still\n",
            "have be\n",
            "through every be the\n",
            "selves nemberous grealy generaled in cars orderinationwaent inflieved of pard of thus world and bissolity, ame \"instincts, betwe ewy witn tranks its that gray, the it fread to reself all wish (spister; and very good play being i\n",
            "------ 온도: 1.2\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through fould mooth be a slowche), intally kmorabonfulness of \"man workt, as an someatter.--things; with cogside\n",
            "truik oneself-head-cleinse, is net an ay abselotic concere\n",
            "eperar mudiatel\n",
            "has christian, of powlees\n",
            "two old proulds of has joys\n",
            "yread arisely waeturline retiently minderturish asy noaverearg nacrery,\n",
            "of brousaund s\n",
            "hay poet the mul to wades him or gofwhiegme not endry.\n",
            "thoys; he\n",
            "sommines )f\n",
            "revo\n",
            "에포크 2\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.5253\n",
            "--- 시드 텍스트: \"the slowly ascending ranks and classes, in which,\n",
            "through fo\"\n",
            "------ 온도: 0.2\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through fore and success and the superful and success of the same and the good the same have the superful and such a conscience of the same as a still the more of the profesterious and the believe the superful the same and the sense and same and the more are as the destruction in the fact the soul, and the man in the proves the superful and the promes and the fact the superful and the proves the conscience \n",
            "------ 온도: 0.5\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for the conscience, he part distingual of\n",
            "the spirit to prove there as the varietic he in allow to dom, where religious must like be a charses of the dare as the lower there are there is seed to his estimation of believe of the understand soughts and respect success of such all former, in do were as a ciste in the commends they their there is soul and been all the success that sought the virtue of t\n",
            "------ 온도: 1.0\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through fores far one's dmand. in relation and venered and even frued; awausing.theoternans\n",
            "had net timtiessears even is in earme of higherty which in not without protable\n",
            "the part, this garde.--an interprety, which feel in what here upon the rage part it. man his our own of absolute us express veelrest many\n",
            "over classful foreb's nameles.\n",
            "to german nej the brume in the deed on the su:d to be beally dmatius \n",
            "------ 온도: 1.2\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for what\n",
            "happen; beontsj,lbie noble is baluring\n",
            "there is metqure will requigere arravely who higher lake. dee sometot.,\n",
            "disturent,\n",
            "licuno, find trringth saugblem thus.\n",
            "\n",
            "toran, artwacs are shact, boods\" storsa; camacterate as word of\n",
            "ramy mage but approces\n",
            "tru knowed. yetters, claime whateher te perfuliy times. =lowing manfwhouse the vinhide of sered because \"the hom old mor live--herevalies to realf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkqavQs2IkTg"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}